import torch
def test_matmul_1x2_2x4(snapshot):
    a = torch.tensor([[-302.6639709472656,-837.3680419921875]])
    b = torch.tensor([[-921.3792114257812,-158.25794982910156,-565.2536010742188,-97.10098266601562],[676.7673950195312,225.18016052246094,441.68756103515625,981.2388916015625]])
    c = torch.matmul(a, b)
    assert torch.allclose(c, torch.tensor([[-287835.09375,-140659.6875,-198773.15625,-792269.125]]))
def test_matmul_1x8_8x16(snapshot):
    a = torch.tensor([[740.23583984375,-531.2762451171875,276.59771728515625,-224.1318817138672,966.5719604492188,-461.5667724609375,-560.6271362304688,427.47503662109375]])
    b = torch.tensor([[404.4162902832031,1021.4122314453125,-922.0001831054688,190.96334838867188,-734.2198486328125,-288.19549560546875,-24.819477081298828,244.03805541992188,511.88134765625,-256.7445373535156,478.1317443847656,-267.8668212890625,-447.1414794921875,-156.5992889404297,-806.6600341796875,507.5458679199219],[-570.2770385742188,526.2174072265625,861.488037109375,-555.11865234375,-920.0963745117188,902.45263671875,673.5966796875,473.39862060546875,-552.6466674804688,-485.91278076171875,833.151611328125,411.16510009765625,-1011.9056396484375,785.65234375,311.0921936035156,468.82421875],[-315.923828125,-255.35324096679688,603.3401489257812,-775.9179077148438,697.5725708007812,-1006.9022827148438,-835.342041015625,758.9902954101562,694.3120727539062,-833.5469970703125,-817.9080200195312,-439.8157958984375,947.1451416015625,613.6858520507812,555.2784423828125,-169.32647705078125],[-539.9786376953125,-67.50614929199219,-103.42229461669922,-212.73977661132812,-328.49151611328125,-121.82142639160156,-1008.437255859375,-397.1493835449219,679.4343872070312,914.7027587890625,-842.3121948242188,-149.99522399902344,944.1489868164062,388.164794921875,168.050537109375,-55.92485427856445],[-335.71649169921875,-266.3196105957031,536.3409423828125,161.98724365234375,803.5282592773438,178.8633270263672,-1004.7467651367188,860.9406127929688,-736.0584716796875,-885.008544921875,961.6062622070312,999.4107055664062,-739.9481811523438,-365.31024169921875,515.4595336914062,605.7864379882812],[170.88662719726562,-280.9897766113281,31.120420455932617,642.9722290039062,408.5052185058594,-694.43701171875,332.52850341796875,977.0765380859375,-510.52801513671875,885.8041381835938,-387.39556884765625,414.0222473144531,412.4481506347656,901.0111083984375,499.3231506347656,456.2200012207031],[622.2041625976562,994.8218994140625,299.31884765625,-670.2691650390625,-192.06787109375,-111.120849609375,-664.78076171875,164.23170471191406,-946.5205078125,941.6319580078125,-138.07733154296875,-59.78321075439453,-34.20695877075195,830.4348754882812,-867.6214599609375,735.0435180664062],[-207.5976104736328,-270.3287048339844,-472.1942443847656,-630.4496459960938,469.68408203125,641.930908203125,459.1016845703125,373.21136474609375,-964.5571899414062,255.94436645507812,1019.2068481445312,-619.9960327148438,635.1891479492188,701.328125,-440.48388671875,753.2805786132812]])
    c = torch.matmul(a, b)
    assert torch.allclose(c, torch.tensor([[-204956.328125,-379985.15625,-815732.5625,235411.15625,1108474,-113867,-936964.5,676729.875,354793.3125,-2050245.625,1495220.125,38626.53125,-357905.125,-1385314.25,-80597.296875,377211.1875]]))
def test_matmul_multi_2x3_3x2_2x4_4x2(snapshot):
    a = torch.tensor([[803.875,329.1087341308594,690.9684448242188],[870.8038940429688,283.5716247558594,-546.4125366210938]])
    b = torch.tensor([[-421.4267578125,-1005.5994873046875],[924.0240478515625,-826.9221801757812],[-518.3827514648438,650.4935302734375]])
    c = torch.matmul(a, b)
    d = torch.tensor([[120.07821655273438,-162.7379913330078,398.11572265625,-739.593017578125],[683.6011352539062,-916.1008911132812,-428.4651794433594,892.9178466796875]])
    e = torch.tensor([[-728.7808837890625,-446.03887939453125],[-900.9910888671875,354.25128173828125],[746.4159545898438,-557.7615356445312],[-264.1495666503906,-274.3820495605469]])
    f = torch.matmul(d, e)
    g = torch.matmul(c, f)
    assert torch.allclose(g, torch.tensor([[-72535244800,452212031488],[433209180160,908101025792]]))
